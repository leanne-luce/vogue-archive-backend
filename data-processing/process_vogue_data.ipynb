{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vogue Archive Data Processing\n",
    "\n",
    "This notebook processes Vogue magazine data and creates vector embeddings for semantic search.\n",
    "\n",
    "**Run this in Google Colab for free GPU access**\n",
    "\n",
    "Runtime: ~20 minutes for 10k records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "!pip install sentence-transformers pinecone pandas tqdm pyarrow"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nfrom pinecone import Pinecone, ServerlessSpec\n\n# Your Pinecone API key\nPINECONE_API_KEY = \"pcsk_2JKS4Y_LNuT72kmgxsuWksy2LyqcQP5Q2iX626vPCwb2KEjj23Vf72a43ZWgNp6FcCJshz\"\nINDEX_NAME = \"vogue-archive\"\n\n# Initialize Pinecone\npc = Pinecone(api_key=PINECONE_API_KEY)\n\n# Create index if it doesn't exist\nif INDEX_NAME not in pc.list_indexes().names():\n    pc.create_index(\n        name=INDEX_NAME,\n        dimension=384,  # all-MiniLM-L6-v2 dimension\n        metric=\"cosine\",\n        spec=ServerlessSpec(\n            cloud=\"aws\",\n            region=\"us-east-1\"\n        )\n    )\n\nindex = pc.Index(INDEX_NAME)\nprint(f\"Index '{INDEX_NAME}' ready!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load the model (lightweight, works on free Colab)\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(f\"Model loaded. Embedding dimension: {model.get_sentence_embedding_dimension()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Load Vogue Runway Data\n\nTwo options:\n\n**Option A: Use the download script (Recommended)**\n1. Run `download_vogue_data.py` on your computer first\n2. Upload the generated `vogue_runway_prepared.json` file to Colab\n\n**Option B: Download directly in Colab (shown below)**"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import json\nimport pandas as pd\n\n# Option A: Upload the prepared JSON file from download_vogue_data.py\n# Uncomment and run this if you have the file:\n# from google.colab import files\n# uploaded = files.upload()  # Upload vogue_runway_prepared.json\n# with open('vogue_runway_prepared.json', 'r') as f:\n#     vogue_items = json.load(f)\n\n# Option B: Download directly in Colab (small subset)\nimport requests\n\nprint(\"Downloading Vogue Runway metadata...\")\nurl = \"https://archive.org/download/VogueRunway_dataset/VogueRunway.parquet\"\n\n# Download parquet file\nresponse = requests.get(url, stream=True)\nwith open('VogueRunway.parquet', 'wb') as f:\n    for chunk in response.iter_content(chunk_size=8192):\n        f.write(chunk)\n\nprint(\"Loading metadata...\")\ndf = pd.read_parquet('VogueRunway.parquet')\n\nprint(f\"Total items: {len(df):,}\")\nprint(f\"Columns: {df.columns.tolist()}\")\n\n# Take top 1000 items by aesthetic score\nif 'aesthetic' in df.columns:\n    df = df.nlargest(1000, 'aesthetic')\nelse:\n    df = df.head(1000)\n\n# Convert to format for embedding\nvogue_items = []\nfor idx, row in df.iterrows():\n    # Create description from metadata\n    desc_parts = []\n    if pd.notna(row.get('designer')):\n        desc_parts.append(f\"{row['designer']}\")\n    if pd.notna(row.get('season')) and pd.notna(row.get('year')):\n        desc_parts.append(f\"{row['season']} {row['year']}\")\n    if pd.notna(row.get('category')):\n        desc_parts.append(f\"{row['category']}\")\n    if pd.notna(row.get('section')):\n        desc_parts.append(f\"{row['section']}\")\n    if pd.notna(row.get('city')):\n        desc_parts.append(f\"from {row['city']} Fashion Week\")\n    \n    description = \" \".join(desc_parts)\n    \n    vogue_items.append({\n        \"id\": f\"vogue_runway_{row['key']}\",\n        \"description\": description,\n        \"metadata\": {\n            \"designer\": str(row.get('designer', '')),\n            \"season\": str(row.get('season', '')),\n            \"year\": int(row.get('year', 0)) if pd.notna(row.get('year')) else 0,\n            \"category\": str(row.get('category', '')),\n            \"city\": str(row.get('city', '')),\n            \"section\": str(row.get('section', '')),\n            \"image_url\": row.get('url', ''),\n            \"aesthetic_score\": float(row.get('aesthetic', 0)) if pd.notna(row.get('aesthetic')) else 0,\n        }\n    })\n\nprint(f\"\\nPrepared {len(vogue_items)} items for embedding\")\nprint(f\"\\nSample item:\")\nprint(json.dumps(vogue_items[0], indent=2))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create Embeddings and Upload to Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from tqdm import tqdm\n\n# Batch size for uploading\nBATCH_SIZE = 100\n\ndef process_batch(batch_items):\n    \"\"\"Process a batch of Vogue items and upload to Pinecone\"\"\"\n    vectors = []\n    \n    for item in batch_items:\n        # Use the description we already created\n        text = item['description']\n        \n        # Generate embedding\n        embedding = model.encode(text).tolist()\n        \n        # Prepare metadata for Pinecone\n        metadata = {\n            \"description\": item['description'],\n            \"designer\": item['metadata']['designer'],\n            \"season\": item['metadata']['season'],\n            \"year\": item['metadata']['year'],\n            \"category\": item['metadata']['category'],\n            \"city\": item['metadata']['city'],\n            \"section\": item['metadata']['section'],\n            \"image_url\": item['metadata']['image_url'],\n            \"aesthetic_score\": item['metadata']['aesthetic_score'],\n        }\n        \n        vectors.append({\n            \"id\": item['id'],\n            \"values\": embedding,\n            \"metadata\": metadata\n        })\n    \n    # Upload to Pinecone\n    index.upsert(vectors=vectors)\n    return len(vectors)\n\n# Process all items in batches\nprint(f\"\\nProcessing {len(vogue_items)} items in batches of {BATCH_SIZE}...\")\ntotal_uploaded = 0\n\nfor i in tqdm(range(0, len(vogue_items), BATCH_SIZE)):\n    batch = vogue_items[i:i+BATCH_SIZE]\n    count = process_batch(batch)\n    total_uploaded += count\n\nprint(f\"\\nâœ“ Upload complete! {total_uploaded} vectors uploaded to Pinecone.\")\nprint(f\"\\nIndex stats: {index.describe_index_stats()}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test a search query\n",
    "query = \"elegant evening gowns from the 1950s\"\n",
    "query_embedding = model.encode(query).tolist()\n",
    "\n",
    "results = index.query(\n",
    "    vector=query_embedding,\n",
    "    top_k=5,\n",
    "    include_metadata=True\n",
    ")\n",
    "\n",
    "print(f\"\\nSearch results for: '{query}'\\n\")\n",
    "for match in results['matches']:\n",
    "    print(f\"Score: {match['score']:.3f}\")\n",
    "    print(f\"ID: {match['id']}\")\n",
    "    print(f\"Description: {match['metadata']['description']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done!\n",
    "\n",
    "Your Vogue archive is now searchable in Pinecone.\n",
    "\n",
    "Next steps:\n",
    "1. Deploy the API (see `../api/`)\n",
    "2. Connect your React Native app"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}